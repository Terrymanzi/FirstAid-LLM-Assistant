{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5TKdKyUlAuk"
      },
      "source": [
        "# **FirstAid Generative QA Assistant** - Using LoRA Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsjaQhvmlPHu"
      },
      "source": [
        "### **ENV SETUP:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pswtP7o7k-rB"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers datasets peft accelerate bitsandbytes trl evaluate rouge_score gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dme9Q3bSlXLA"
      },
      "source": [
        "### IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsqLV-BMlfxI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEuA_YZDlktz"
      },
      "source": [
        "### LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ULoML_Slo_A"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"i-am-mushfiq/FirstAidQA\")\n",
        "dataset\n",
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GunYIMflt12"
      },
      "source": [
        "### Train / Validation Split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2V9U0vQl2n1"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = dataset[\"train\"]\n",
        "val_dataset = dataset[\"test\"]\n",
        "\n",
        "print(len(train_dataset), len(val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BffFVCB3l4wq"
      },
      "source": [
        "### System Instruction Formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HwnNRtemAt7"
      },
      "outputs": [],
      "source": [
        "def format_prompt(example):\n",
        "    return f\"\"\"### Instruction:\n",
        "You are a professional first aid assistant.\n",
        "Provide clear, step-by-step emergency guidance.\n",
        "This is for educational purposes only.\n",
        "\n",
        "Question:\n",
        "{example['question']}\n",
        "\n",
        "### Response:\n",
        "{example['answer']}\"\"\"\n",
        "\n",
        "## Apply formatting:\n",
        "train_dataset = train_dataset.map(lambda x: {\"text\": format_prompt(x)})\n",
        "val_dataset = val_dataset.map(lambda x: {\"text\": format_prompt(x)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTdQvVEbmCPK"
      },
      "source": [
        "### Load Tokenizer & Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06FkQLdymQdU"
      },
      "outputs": [],
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezXjvgHkmSVq"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub8QCRBRmVZI"
      },
      "outputs": [],
      "source": [
        "max_length = 512\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmf1sNAcmXE_"
      },
      "source": [
        "### Re-usable Experiment Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cfjzes6mdZM"
      },
      "outputs": [],
      "source": [
        "def run_experiment(exp_name, learning_rate, lora_rank, epochs):\n",
        "\n",
        "    print(f\"\\nRunning {exp_name}\")\n",
        "\n",
        "    # Apply LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        r=lora_rank,\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\"\n",
        "    )\n",
        "\n",
        "    lora_model = get_peft_model(model, lora_config)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./{exp_name}\",\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=8,\n",
        "        learning_rate=learning_rate,\n",
        "        num_train_epochs=epochs,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        fp16=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=lora_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    lora_model.save_pretrained(f\"{exp_name}_adapter\")\n",
        "\n",
        "    return {\n",
        "        \"experiment\": exp_name,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"lora_rank\": lora_rank,\n",
        "        \"epochs\": epochs,\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_sec\": training_time\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_tnMpSmgTK"
      },
      "source": [
        "### Runnning all (3) Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdx8Lq7ZmnjJ"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "results.append(run_experiment(\"exp1\", 2e-4, 16, 2))\n",
        "results.append(run_experiment(\"exp2\", 5e-5, 16, 3))\n",
        "results.append(run_experiment(\"exp3\", 2e-4, 32, 1))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df\n",
        "\n",
        "# saving results\n",
        "results_df.to_csv(\"experiment_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNEAST3amvaE"
      },
      "source": [
        "### **Evaluation (BLEU & ROUGE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YqaPyicmxtC"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# generate predictions:\n",
        "def generate_answer(question, model):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "You are a professional first aid assistant.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=200)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# test on validation dataset:\n",
        "sample = val_dataset.select(range(50))\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for example in sample:\n",
        "    question = example[\"text\"].split(\"Question:\")[1].split(\"### Response:\")[0].strip()\n",
        "    reference = example[\"text\"].split(\"### Response:\")[1].strip()\n",
        "\n",
        "    pred = generate_answer(question, model)\n",
        "\n",
        "    predictions.append(pred)\n",
        "    references.append([reference])\n",
        "\n",
        "# compute metrics:\n",
        "bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "rouge_score = rouge.compute(predictions=predictions, references=[r[0] for r in references])\n",
        "\n",
        "print(\"BLEU:\", bleu_score)\n",
        "print(\"ROUGE:\", rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoZRLVilnIg6"
      },
      "source": [
        "### Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S51qumIjnLjR"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def compute_perplexity(eval_loss):\n",
        "    return math.exp(eval_loss)\n",
        "\n",
        "results_df[\"perplexity\"] = results_df[\"eval_loss\"].apply(compute_perplexity)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnvfI8KcnNEY"
      },
      "source": [
        "### Base Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOa8tR9KnR3r"
      },
      "outputs": [],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(generate_answer(\"How do I treat a burn?\", base_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk6JR47InT7u"
      },
      "source": [
        "### Gradio App Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YlSERMmnW-i"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chatbot(question):\n",
        "    return generate_answer(question, model)\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=chatbot,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"FirstAid Emergency Assistant\",\n",
        "    description=\"Educational purposes only. Not a substitute for professional medical advice.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ3bwKPynfTz"
      },
      "source": [
        "### Saving the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYeEdfC7nbH6"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"final_firstaid_model\")\n",
        "tokenizer.save_pretrained(\"final_firstaid_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
